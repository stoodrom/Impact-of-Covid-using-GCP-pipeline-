{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9128cd-af23-4f51-86b8-c8a3f3b1406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description      effective_local  \\\n",
      "0  * WHAT...West winds 20 to 25 mph with gusts up...  2024-12-04T04:18:00   \n",
      "1  * WHAT...The South Coast AQMD has issued a man...  2024-12-03T16:09:00   \n",
      "2  * WHAT...West winds 20 to 25 mph with gusts up...  2024-12-04T09:04:00   \n",
      "3  * WHAT...Dangerous rip currents.\\n\\n* WHERE......  2024-12-04T00:57:00   \n",
      "4  Fog will continue to slowly lift and scatter o...  2024-12-04T09:51:00   \n",
      "\n",
      "         effective_utc           ends_local             ends_utc  \\\n",
      "0  2024-12-04T09:18:00  2024-12-05T22:00:00  2024-12-06T03:00:00   \n",
      "1  2024-12-04T00:09:00  2024-12-05T00:00:00  2024-12-05T08:00:00   \n",
      "2  2024-12-04T15:04:00  2024-12-05T00:00:00  2024-12-05T06:00:00   \n",
      "3  2024-12-04T05:57:00  2024-12-04T19:00:00  2024-12-05T00:00:00   \n",
      "4  2024-12-04T17:51:00  2024-12-04T10:00:00  2024-12-04T18:00:00   \n",
      "\n",
      "         expires_local          expires_utc          onset_local  \\\n",
      "0  2024-12-04T17:00:00  2024-12-04T22:00:00  2024-12-05T06:00:00   \n",
      "1  2024-12-05T00:00:00  2024-12-05T08:00:00  2024-12-03T16:09:00   \n",
      "2  2024-12-04T17:15:00  2024-12-04T23:15:00  2024-12-04T14:00:00   \n",
      "3  2024-12-04T19:00:00  2024-12-05T00:00:00  2024-12-04T00:57:00   \n",
      "4  2024-12-04T11:00:00  2024-12-04T19:00:00  2024-12-04T09:51:00   \n",
      "\n",
      "             onset_utc                                            regions  \\\n",
      "0  2024-12-05T11:00:00  [Northern Fairfield,  Northern New Haven,  Nor...   \n",
      "1  2024-12-04T00:09:00  [Catalina and Santa Barbara Islands,  Santa Cl...   \n",
      "2  2024-12-04T20:00:00  [Winnebago,  Boone,  McHenry,  Lake,  Ogle,  L...   \n",
      "3  2024-12-04T05:57:00  [Coastal Palm Beach County,  Coastal Broward C...   \n",
      "4  2024-12-04T17:51:00  [Southwest Interior,  Everett and Vicinity,  T...   \n",
      "\n",
      "   severity                                              title  \\\n",
      "0  Advisory  Wind Advisory issued December 4 at 4:18AM EST ...   \n",
      "1  Advisory  Air Quality Alert issued December 3 at 4:09PM ...   \n",
      "2  Advisory  Wind Advisory issued December 4 at 9:04AM CST ...   \n",
      "3     Watch  Rip Current Statement issued December 4 at 12:...   \n",
      "4  Advisory  Dense Fog Advisory issued December 4 at 9:51AM...   \n",
      "\n",
      "                                                 uri         city  \n",
      "0  https://api.weather.gov/alerts/urn:oid:2.49.0....     New York  \n",
      "1  https://api.weather.gov/alerts/urn:oid:2.49.0....  Los Angeles  \n",
      "2  https://api.weather.gov/alerts/urn:oid:2.49.0....      Chicago  \n",
      "3  https://api.weather.gov/alerts/urn:oid:2.49.0....        Miami  \n",
      "4  https://api.weather.gov/alerts/urn:oid:2.49.0....      Seattle  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = '04220a7214974d03aea163f7dccd1535'\n",
    "\n",
    "# List of cities to check for weather alerts\n",
    "cities = ['Atlanta', 'New York', 'Los Angeles', 'Chicago', 'Miami', 'Dallas', 'Seattle']\n",
    "\n",
    "# Store the results in a list\n",
    "alerts_data = []\n",
    "\n",
    "# Iterate through each city and fetch weather alerts\n",
    "for city in cities:\n",
    "    url = f\"https://api.weatherbit.io/v2.0/alerts?city={city}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract alerts if present\n",
    "        if \"alerts\" in data and data[\"alerts\"]:\n",
    "            for alert in data[\"alerts\"]:\n",
    "                alert[\"city\"] = city  # Add city name to each alert\n",
    "                alerts_data.append(alert)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {city}. Status Code: {response.status_code}\")\n",
    "\n",
    "# Convert the alerts data into a DataFrame for better visualization\n",
    "df = pd.DataFrame(alerts_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No alerts found for the specified cities.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cea43cd-09aa-4d56-99c1-000c0fcbe218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas google-cloud-bigquery requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdbd070-90e2-4d48-abb5-42af5b206916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\priya\\Downloads\\datamanagement-443620-c2447c7bc4d3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c13c644-a861-4745-bcd5-8fbd03b22af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description      effective_local  \\\n",
      "0  * WHAT...West winds 20 to 25 mph with gusts up...  2024-12-04T04:18:00   \n",
      "1  * WHAT...The South Coast AQMD has issued a man...  2024-12-03T16:09:00   \n",
      "2  * WHAT...West winds 20 to 25 mph with gusts up...  2024-12-04T09:04:00   \n",
      "3  * WHAT...Dangerous rip currents.\\n\\n* WHERE......  2024-12-04T00:57:00   \n",
      "4  Fog will continue to slowly lift and scatter o...  2024-12-04T09:51:00   \n",
      "\n",
      "         effective_utc           ends_local             ends_utc  \\\n",
      "0  2024-12-04T09:18:00  2024-12-05T22:00:00  2024-12-06T03:00:00   \n",
      "1  2024-12-04T00:09:00  2024-12-05T00:00:00  2024-12-05T08:00:00   \n",
      "2  2024-12-04T15:04:00  2024-12-05T00:00:00  2024-12-05T06:00:00   \n",
      "3  2024-12-04T05:57:00  2024-12-04T19:00:00  2024-12-05T00:00:00   \n",
      "4  2024-12-04T17:51:00  2024-12-04T10:00:00  2024-12-04T18:00:00   \n",
      "\n",
      "         expires_local          expires_utc          onset_local  \\\n",
      "0  2024-12-04T17:00:00  2024-12-04T22:00:00  2024-12-05T06:00:00   \n",
      "1  2024-12-05T00:00:00  2024-12-05T08:00:00  2024-12-03T16:09:00   \n",
      "2  2024-12-04T17:15:00  2024-12-04T23:15:00  2024-12-04T14:00:00   \n",
      "3  2024-12-04T19:00:00  2024-12-05T00:00:00  2024-12-04T00:57:00   \n",
      "4  2024-12-04T11:00:00  2024-12-04T19:00:00  2024-12-04T09:51:00   \n",
      "\n",
      "             onset_utc                                            regions  \\\n",
      "0  2024-12-05T11:00:00  [Northern Fairfield,  Northern New Haven,  Nor...   \n",
      "1  2024-12-04T00:09:00  [Catalina and Santa Barbara Islands,  Santa Cl...   \n",
      "2  2024-12-04T20:00:00  [Winnebago,  Boone,  McHenry,  Lake,  Ogle,  L...   \n",
      "3  2024-12-04T05:57:00  [Coastal Palm Beach County,  Coastal Broward C...   \n",
      "4  2024-12-04T17:51:00  [Southwest Interior,  Everett and Vicinity,  T...   \n",
      "\n",
      "   severity                                              title  \\\n",
      "0  Advisory  Wind Advisory issued December 4 at 4:18AM EST ...   \n",
      "1  Advisory  Air Quality Alert issued December 3 at 4:09PM ...   \n",
      "2  Advisory  Wind Advisory issued December 4 at 9:04AM CST ...   \n",
      "3     Watch  Rip Current Statement issued December 4 at 12:...   \n",
      "4  Advisory  Dense Fog Advisory issued December 4 at 9:51AM...   \n",
      "\n",
      "                                                 uri         city  \n",
      "0  https://api.weather.gov/alerts/urn:oid:2.49.0....     New York  \n",
      "1  https://api.weather.gov/alerts/urn:oid:2.49.0....  Los Angeles  \n",
      "2  https://api.weather.gov/alerts/urn:oid:2.49.0....      Chicago  \n",
      "3  https://api.weather.gov/alerts/urn:oid:2.49.0....        Miami  \n",
      "4  https://api.weather.gov/alerts/urn:oid:2.49.0....      Seattle  \n",
      "Dataset WeatherData created or already exists.\n",
      "Table WeatherTable created or already exists.\n",
      "Data loaded into BigQuery successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import SchemaField\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = '04220a7214974d03aea163f7dccd1535'\n",
    "\n",
    "# List of cities to check for weather alerts\n",
    "cities = ['Atlanta', 'New York', 'Los Angeles', 'Chicago', 'Miami', 'Dallas', 'Seattle']\n",
    "\n",
    "# Store the results in a list\n",
    "alerts_data = []\n",
    "\n",
    "# Iterate through each city and fetch weather alerts\n",
    "for city in cities:\n",
    "    url = f\"https://api.weatherbit.io/v2.0/alerts?city={city}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract alerts if present\n",
    "        if \"alerts\" in data and data[\"alerts\"]:\n",
    "            for alert in data[\"alerts\"]:\n",
    "                alert[\"city\"] = city  # Add city name to each alert\n",
    "                alerts_data.append(alert)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {city}. Status Code: {response.status_code}\")\n",
    "\n",
    "# Convert the alerts data into a DataFrame\n",
    "df = pd.DataFrame(alerts_data)\n",
    "\n",
    "# Print the DataFrame to verify the data\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No alerts found for the specified cities.\")\n",
    "\n",
    "# Load data into BigQuery\n",
    "project_id = \"datamanagement-443620\"\n",
    "dataset_id = \"WeatherData\"\n",
    "table_id = \"WeatherTable\"\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define table schema\n",
    "schema = [\n",
    "    SchemaField(\"title\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    SchemaField(\"severity\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    SchemaField(\"effective\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    SchemaField(\"expires\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    SchemaField(\"city\", \"STRING\", mode=\"NULLABLE\"),  # Add city field\n",
    "]\n",
    "\n",
    "# Create the dataset if it doesn't exist\n",
    "dataset_ref = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "try:\n",
    "    client.create_dataset(dataset_ref, exists_ok=True)\n",
    "    print(f\"Dataset {dataset_id} created or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating dataset: {e}\")\n",
    "\n",
    "# Create the table if it doesn't exist\n",
    "table_ref = bigquery.Table(f\"{project_id}.{dataset_id}.{table_id}\", schema=schema)\n",
    "try:\n",
    "    client.create_table(table_ref, exists_ok=True)\n",
    "    print(f\"Table {table_id} created or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating table: {e}\")\n",
    "\n",
    "# Load data into BigQuery\n",
    "if not df.empty:\n",
    "    job = client.load_table_from_dataframe(df, table_ref)\n",
    "    job.result()  # Wait for the job to complete\n",
    "    print(\"Data loaded into BigQuery successfully!\")\n",
    "else:\n",
    "    print(\"No data to load into BigQuery.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397379b3-5c39-4586-8e98-c462c9a25554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery-storage\n",
      "  Downloading google_cloud_bigquery_storage-2.27.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (2.23.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery-storage) (2.36.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery-storage) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-cloud-bigquery-storage) (5.29.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (2.32.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (1.68.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage) (2024.8.30)\n",
      "Downloading google_cloud_bigquery_storage-2.27.0-py2.py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.0 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 20.5/240.0 kB 682.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 204.8/240.0 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 240.0/240.0 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: google-cloud-bigquery-storage\n",
      "Successfully installed google-cloud-bigquery-storage-2.27.0\n"
     ]
    }
   ],
   "source": [
    "#pip install db-dtypes\n",
    "!pip install google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f68ce08c-af68-49ac-b3b2-7011f362854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [regions, alert_count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "query = f\"\"\"\n",
    "    SELECT * FROM datamanagement-443620.WeatherData.WeatherTable\n",
    "\"\"\"\n",
    "# # Run the query and load data into a DataFrame\n",
    "df = client.query(query).to_dataframe()\n",
    "\n",
    "# Transformation 1: Combine effective_local and effective_utc into one datetime column\n",
    "df[\"effective_combined\"] = df[\"effective_local\"].fillna(df[\"effective_utc\"])\n",
    "\n",
    "# Transformation 2: Filter alerts with severity \"Severe\"\n",
    "filtered_df = df[df[\"severity\"] == \"Severe\"]\n",
    "\n",
    "# Transformation 3: Group by region and count alerts\n",
    "transformed_df = filtered_df.groupby(\"regions\").size().reset_index(name=\"alert_count\")\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15ad77a4-bfd7-4a08-a03f-b4133c9ff8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetListItem' object has no attribute 'WeatherData'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets in project:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mWeatherData\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo datasets found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetListItem' object has no attribute 'WeatherData'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List datasets in the project\n",
    "datasets = list(client.list_datasets())\n",
    "if datasets:\n",
    "    print(\"Datasets in project:\")\n",
    "    for dataset in datasets:\n",
    "        print(f\" - {dataset.WeatherData}\")\n",
    "else:\n",
    "    print(\"No datasets found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548db86-991c-4b04-a032-1f3cd2fd2147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
